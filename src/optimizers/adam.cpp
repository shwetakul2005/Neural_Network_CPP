#include "../layers/layer.hpp"
#include "optimizer.hpp"
#include <iostream>
#include "adam.hpp"

// Adam::Adam (double lr = 0.001, double beta1 = 0.9, double beta2 = 0.999, double epsilon = 1e-8){
//     learning_rate_ = 0.001;
//     beta1_ = beta1;
//     beta2_ = beta2;
//     epsilon_ = epsilon;
// }

// void Adam::step(Layer& layer) {

// }